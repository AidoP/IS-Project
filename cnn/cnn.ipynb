{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bit00b0fb020ed641dc9f703e66ba6f18d4",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "255e8562cb7d51ff2d4f13faf9db7f5ecc553585d93da45825d5a9294c7a766b"
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Definitions\n",
    "```\n",
    "$ pip freeze\n",
    "tensorflow\n",
    "scikit-image\n",
    "scikit-learn\n",
    "imutils\n",
    "opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import numpy\n",
    "import skimage.io as scikit_io\n",
    "import skimage.transform as scikit_transform\n",
    "import matplotlib.pyplot as matplot_plot\n",
    "import matplotlib.image as matplot_image\n",
    "import sklearn.model_selection as scikit_model_selection\n",
    "import os\n",
    "import random\n",
    "import imutils\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "INPUT_SIZE = 128\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def load_image(path):\n",
    "            image = scikit_io.imread(path)\n",
    "            return scikit_transform.resize(image, (INPUT_SIZE, INPUT_SIZE), anti_aliasing = True)\n",
    "\n",
    "        def show_image(image):\n",
    "            matplot_plot.imshow(image)\n",
    "            matplot_plot.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_dir = \"../image-puller/images/\"\n",
    "dataset_dir = \"images/\"\n",
    "labels = [\"men\", \"women\"]\n",
    "\n",
    "random.seed(1)\n",
    "test_train_ratio = 0.2\n",
    "\n",
    "# Copy images from source into split directories of train / test for the given label\n",
    "def prepare_directory(source, label):\n",
    "    for image_path in os.listdir(source):\n",
    "        if (image_path.endswith(\".png\")):\n",
    "            image_set = \"test\" if random.random() < test_train_ratio else \"train\"\n",
    "            destination = os.path.join(dataset_dir, image_set, label, image_path)\n",
    "            scikit_io.imsave(destination, load_image(os.path.join(source, image_path)))\n",
    "def prepare(label):\n",
    "    prepare_directory(os.path.join(datasource_dir, label), label)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the directories\n",
    "for split_dir in [\"train/\", \"test/\"]:\n",
    "    for label in labels:\n",
    "        os.makedirs(dataset_dir + split_dir + label + \"/\", exist_ok = True)\n",
    "\n",
    "# Copy the images over\n",
    "prepare(\"men\")\n",
    "prepare(\"women\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the images into training, testing and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile(images):\n",
    "    dataset = numpy.ndarray((len(images), INPUT_SIZE, INPUT_SIZE, CHANNELS), dtype = numpy.uint8)\n",
    "    labels = numpy.ndarray((len(images)), dtype = numpy.uint8)\n",
    "    for index, image in enumerate(images):\n",
    "        image_data = scikit_io.imread(image)\n",
    "        # Remove greyscale images\n",
    "        if (len(image_data.shape) != 3):\n",
    "            image_data = numpy.stack([image_data]*3, axis = -1)\n",
    "        dataset[index] = image_data\n",
    "        labels[index] = 0 if \"women\" in image else 1\n",
    "    return dataset, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = list(imutils.paths.list_images(dataset_dir + \"train/\"))\n",
    "training_images_men = list(imutils.paths.list_images(dataset_dir + \"train/men/\"))\n",
    "training_images_women = list(imutils.paths.list_images(dataset_dir + \"train/women/\"))\n",
    "testing_images_men = list(imutils.paths.list_images(dataset_dir + \"test/men/\"))\n",
    "testing_images_women = list(imutils.paths.list_images(dataset_dir + \"test/women/\"))\n",
    "testing_images = training_images_men + training_images_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE_HALF = 1000\n",
    "VALIDATION_SIZE_HALF = TRAINING_SIZE_HALF + 500\n",
    "training_data, training_labels = compile(training_images_men[:TRAINING_SIZE_HALF] + training_images_women[:TRAINING_SIZE_HALF])\n",
    "validation_data, validation_labels = compile(training_images_men[TRAINING_SIZE_HALF:VALIDATION_SIZE_HALF] + training_images_women[TRAINING_SIZE_HALF:VALIDATION_SIZE_HALF])\n",
    "testing_data, testing_images = compile(testing_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten the images into one numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, 3, input_shape = [128, 128, 3], padding = \"same\", activation = \"relu\", name = \"convolution_first\"),\n",
    "        keras.layers.Conv2D(32, 3, padding = \"same\", activation = \"relu\", name = \"convolution_second\"),\n",
    "        keras.layers.MaxPool2D(pool_size = (2, 2), padding = \"valid\", name = \"pooling_first\"),\n",
    "        keras.layers.Conv2D(64, 3, padding = \"same\", activation = \"relu\", name = \"convolution_small_first\"),\n",
    "        keras.layers.Conv2D(64, 3, padding = \"same\", activation = \"relu\", name = \"convolution_small_second\"),\n",
    "        keras.layers.MaxPool2D(pool_size = (2, 2), padding = \"valid\", name = \"pooling_second\"),\n",
    "        keras.layers.Flatten(name = \"flatten\"),\n",
    "        keras.layers.Dense(256, activation = \"relu\", name = \"fully_connected_1\"),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(256, activation = \"relu\", name = \"fully_connected_2\"),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation = \"relu\", name = \"classification\"),\n",
    "        keras.layers.Activation(\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = keras.optimizers.RMSprop(learning_rate=1e-4), metrics = [ \"accuracy\" ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconvolution_first (Conv2D)   (None, 128, 128, 32)      896       \n_________________________________________________________________\nconvolution_second (Conv2D)  (None, 128, 128, 32)      9248      \n_________________________________________________________________\npooling_first (MaxPooling2D) (None, 64, 64, 32)        0         \n_________________________________________________________________\nconvolution_small_first (Con (None, 64, 64, 64)        18496     \n_________________________________________________________________\nconvolution_small_second (Co (None, 64, 64, 64)        36928     \n_________________________________________________________________\npooling_second (MaxPooling2D (None, 32, 32, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 65536)             0         \n_________________________________________________________________\nfully_connected_1 (Dense)    (None, 256)               16777472  \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 256)               0         \n_________________________________________________________________\nfully_connected_2 (Dense)    (None, 256)               65792     \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 256)               0         \n_________________________________________________________________\nclassification (Dense)       (None, 1)                 257       \n_________________________________________________________________\nactivation_2 (Activation)    (None, 1)                 0         \n=================================================================\nTotal params: 16,909,089\nTrainable params: 16,909,089\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "barnet = create_model()\n",
    "barnet.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.History(),\n",
    "    keras.callbacks.EarlyStopping(monitor = \"loss\", patience = 10, verbose = 1, mode = \"auto\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/50\n125/125 - 71s - loss: 0.7743 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 2/50\n125/125 - 70s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 3/50\n125/125 - 69s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 4/50\n125/125 - 69s - loss: 0.6928 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 5/50\n125/125 - 68s - loss: 0.6928 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 6/50\n125/125 - 78s - loss: 0.7086 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 7/50\n125/125 - 71s - loss: 0.6941 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 8/50\n125/125 - 70s - loss: 0.6928 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 9/50\n125/125 - 70s - loss: 0.6987 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 10/50\n125/125 - 69s - loss: 0.6925 - accuracy: 0.5010 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 11/50\n125/125 - 70s - loss: 0.7133 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 12/50\n125/125 - 69s - loss: 0.7134 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 13/50\n125/125 - 71s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 14/50\n125/125 - 73s - loss: 0.6928 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 15/50\n125/125 - 71s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 16/50\n125/125 - 76s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 17/50\n125/125 - 72s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 18/50\n125/125 - 69s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 19/50\n125/125 - 70s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 20/50\n125/125 - 71s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 00020: early stopping\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x214e7072910>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barnet.fit(training_data, training_labels, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data = (validation_data, validation_labels), verbose = 2, shuffle = True, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "32/32 [==============================] - 7s 204ms/step - loss: 0.6931 - accuracy: 0.5000\nLoss: 0.6931474804878235\nAccuracy: 0.5\n"
    }
   ],
   "source": [
    "test_loss, test_accuracy = barnet.evaluate(validation_data, validation_labels, verbose = 1)\n",
    "print(f\"Loss: {test_loss}\\nAccuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}