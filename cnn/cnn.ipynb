{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "255e8562cb7d51ff2d4f13faf9db7f5ecc553585d93da45825d5a9294c7a766b"
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Definitions\n",
    "```\n",
    "$ pip freeze\n",
    "tensorflow\n",
    "scikit-image\n",
    "scikit-learn\n",
    "imutils\n",
    "opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import numpy\n",
    "import skimage.io as scikit_io\n",
    "import skimage.transform as scikit_transform\n",
    "import matplotlib.pyplot as matplot_plot\n",
    "import matplotlib.image as matplot_image\n",
    "import sklearn.model_selection as scikit_model_selection\n",
    "import os\n",
    "import random\n",
    "from imutils import paths\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "INPUT_SIZE = 128\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def load_image(path):\n",
    "            image = scikit_io.imread(path)\n",
    "            return scikit_transform.resize(image, (INPUT_SIZE, INPUT_SIZE), anti_aliasing = True)\n",
    "\n",
    "        def show_image(image):\n",
    "            matplot_plot.imshow(image)\n",
    "            matplot_plot.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_dir = \"../image-puller/images/\"\n",
    "dataset_dir = \"images/\"\n",
    "labels = [\"men\", \"women\"]\n",
    "\n",
    "random.seed(1)\n",
    "test_train_ratio = 0.2\n",
    "\n",
    "# Copy images from source into split directories of train / test for the given label\n",
    "def prepare_directory(source, label):\n",
    "    for image_path in os.listdir(source):\n",
    "        if (image_path.endswith(\".png\")):\n",
    "            image_set = \"test\" if random.random() < test_train_ratio else \"train\"\n",
    "            destination = os.path.join(dataset_dir, image_set, label, image_path)\n",
    "            scikit_io.imsave(destination, load_image(os.path.join(source, image_path)))\n",
    "def prepare(label):\n",
    "    prepare_directory(os.path.join(datasource_dir, label), label)\n",
    "            "
   ]
  },
  {
   "source": [
    "# Prepare Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the directories\n",
    "for split_dir in [\"train/\", \"test/\"]:\n",
    "    for label in labels:\n",
    "        os.makedirs(dataset_dir + split_dir + label + \"/\", exist_ok = True)\n",
    "\n",
    "# Copy the images over\n",
    "prepare(\"men\")\n",
    "prepare(\"women\")\n"
   ]
  },
  {
   "source": [
    "# Compile the images into training, testing and validation sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile(images):\n",
    "    dataset = numpy.ndarray((len(images), INPUT_SIZE, INPUT_SIZE, CHANNELS), dtype = numpy.uint8)\n",
    "    labels = numpy.ndarray((len(images)), dtype = numpy.uint8)\n",
    "    for index, image in enumerate(images):\n",
    "        image_data = scikit_io.imread(image)\n",
    "        # Remove greyscale images\n",
    "        if (len(image_data.shape) != 3):\n",
    "            image_data = numpy.stack([image_data]*3, axis = -1)\n",
    "        dataset[index] = image_data\n",
    "        labels[index] = 0 if \"women\" in image else 1\n",
    "    return dataset, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = list(imutils.paths.list_images(dataset_dir + \"train/\"))\n",
    "training_images_men = list(imutils.paths.list_images(dataset_dir + \"train/men/\"))\n",
    "training_images_women = list(imutils.paths.list_images(dataset_dir + \"train/women/\"))\n",
    "testing_images_men = list(imutils.paths.list_images(dataset_dir + \"test/men/\"))\n",
    "testing_images_women = list(imutils.paths.list_images(dataset_dir + \"test/women/\"))\n",
    "testing_images = training_images_men + training_images_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE_HALF = 10000\n",
    "VALIDATION_SIZE_HALF = TRAINING_SIZE_HALF + 3000\n",
    "training_data, training_labels = compile(training_images_men[:TRAINING_SIZE_HALF] + training_images_women[:TRAINING_SIZE_HALF])\n",
    "validation_data, validation_labels = compile(training_images_men[TRAINING_SIZE_HALF:VALIDATION_SIZE_HALF] + training_images_women[TRAINING_SIZE_HALF:VALIDATION_SIZE_HALF])\n",
    "testing_data, testing_images = compile(testing_images)"
   ]
  },
  {
   "source": [
    "# Flatten the images into one numpy array"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(16, (8, 8), input_shape = [128, 128, 3], strides = 1, padding = \"same\", activation = \"relu\", name = \"convolution_large\"),\n",
    "        keras.layers.MaxPool2D(pool_size = (2, 2), padding = \"valid\", name = \"pooling\"),\n",
    "        keras.layers.Conv2D(16, (4, 4), input_shape = [64, 64, 16], strides = 1, padding = \"same\", activation = \"relu\", name = \"convolution_small\"),\n",
    "        keras.layers.Flatten(name = \"flatten\"),\n",
    "        keras.layers.Dense(16 * 4 * 4, activation = tensorflow.nn.softmax, name = \"fully_connected_1\"),\n",
    "        keras.layers.Dense(2, activation = tensorflow.nn.softmax, name = \"fully_connected_2\")\n",
    "    ])\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = keras.optimizers.RMSprop(), metrics = [ \"accuracy\" ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "convolution_large (Conv2D)   (None, 128, 128, 16)      3088      \n",
      "_________________________________________________________________\n",
      "pooling (MaxPooling2D)       (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "convolution_small (Conv2D)   (None, 64, 64, 16)        4112      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "fully_connected_1 (Dense)    (None, 256)               16777472  \n",
      "_________________________________________________________________\n",
      "fully_connected_2 (Dense)    (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 16,785,186\n",
      "Trainable params: 16,785,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "barnet = create_model()\n",
    "barnet.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.History(),\n",
    "    keras.callbacks.EarlyStopping(monitor = \"loss\", patience = 10, verbose = 1, mode = \"auto\")\n",
    "]"
   ]
  },
  {
   "source": [
    "# TRAIN!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 - 304s - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "2000/2000 - 299s - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "2000/2000 - 299s - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "2000/2000 - 304s - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "2000/2000 - 303s - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "2000/2000 - 299s - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "2000/2000 - 300s - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "2000/2000 - 305s - loss: 0.6932 - accuracy: 0.5061 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "2000/2000 - 302s - loss: 0.6932 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "2000/2000 - 300s - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "2000/2000 - 304s - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27e428830a0>"
      ]
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "barnet.fit(training_data, training_labels, batch_size = BATCH_SIZE, epochs = 20, validation_data = (validation_data, validation_labels), verbose = 2, shuffle = True, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "188/188 [==============================] - 0s 659us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-378a5d6ea9b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loss: {test_loss}\\nAccuracy: {test_accuracy}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = vgg.evaluate(validation_data, validation_labels, verbose = 1)\n",
    "print(f\"Loss: {test_loss}\\nAccuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}