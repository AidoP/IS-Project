{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "255e8562cb7d51ff2d4f13faf9db7f5ecc553585d93da45825d5a9294c7a766b"
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Definitions\n",
    "```\n",
    "$ pip freeze\n",
    "tensorflow\n",
    "scikit-image\n",
    "scikit-learn\n",
    "imutils\n",
    "opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import numpy\n",
    "import skimage.io as scikit_io\n",
    "import skimage.transform as scikit_transform\n",
    "import matplotlib.pyplot as matplot_plot\n",
    "import matplotlib.image as matplot_image\n",
    "import sklearn.model_selection as scikit_model_selection\n",
    "import os\n",
    "import random\n",
    "from imutils import paths\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "INPUT_SIZE = 128\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def load_image(path):\n",
    "            image = scikit_io.imread(path)\n",
    "            return scikit_transform.resize(image, (INPUT_SIZE, INPUT_SIZE), anti_aliasing = True)\n",
    "\n",
    "        def show_image(image):\n",
    "            matplot_plot.imshow(image)\n",
    "            matplot_plot.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_dir = \"../image-puller/images/\"\n",
    "dataset_dir = \"images/\"\n",
    "labels = [\"men\", \"women\"]\n",
    "\n",
    "random.seed(1)\n",
    "test_train_ratio = 0.2\n",
    "\n",
    "# Copy images from source into split directories of train / test for the given label\n",
    "def prepare_directory(source, label):\n",
    "    for image_path in os.listdir(source):\n",
    "        if (image_path.endswith(\".png\")):\n",
    "            image_set = \"test\" if random.random() < test_train_ratio else \"train\"\n",
    "            destination = os.path.join(dataset_dir, image_set, label, image_path)\n",
    "            scikit_io.imsave(destination, load_image(os.path.join(source, image_path)))\n",
    "def prepare(label):\n",
    "    prepare_directory(os.path.join(datasource_dir, label), label)\n",
    "            "
   ]
  },
  {
   "source": [
    "# Prepare Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the directories\n",
    "for split_dir in [\"train/\", \"test/\"]:\n",
    "    for label in labels:\n",
    "        os.makedirs(dataset_dir + split_dir + label + \"/\", exist_ok = True)\n",
    "\n",
    "# Copy the images over\n",
    "prepare(\"men\")\n",
    "prepare(\"women\")\n"
   ]
  },
  {
   "source": [
    "# Compile the images into training, testing and validation sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile(images):\n",
    "    dataset = numpy.ndarray((len(images), INPUT_SIZE, INPUT_SIZE, CHANNELS), dtype = numpy.uint8)\n",
    "    labels = numpy.ndarray((len(images)), dtype = numpy.uint8)\n",
    "    for index, image in enumerate(images):\n",
    "        image_data = scikit_io.imread(image)\n",
    "        # Remove greyscale images\n",
    "        if (len(image_data.shape) != 3):\n",
    "            image_data = numpy.stack([image_data]*3, axis = -1)\n",
    "        dataset[index] = image_data\n",
    "        labels[index] = 0 if \"women\" in image else 1\n",
    "    return dataset, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = list(imutils.paths.list_images(dataset_dir + \"train/\"))\n",
    "training_images_men = list(imutils.paths.list_images(dataset_dir + \"train/men/\"))\n",
    "training_images_women = list(imutils.paths.list_images(dataset_dir + \"train/women/\"))\n",
    "testing_images_men = list(imutils.paths.list_images(dataset_dir + \"test/men/\"))\n",
    "testing_images_women = list(imutils.paths.list_images(dataset_dir + \"test/women/\"))\n",
    "testing_images = training_images_men + training_images_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE_HALF = 1000\n",
    "VALIDATION_SIZE_HALF = TRAINING_SIZE_HALF + 500\n",
    "training_data, training_labels = compile(training_images_men[:TRAINING_SIZE_HALF] + training_images_women[:TRAINING_SIZE_HALF])\n",
    "validation_data, validation_labels = compile(training_images_men[TRAINING_SIZE_HALF:VALIDATION_SIZE_HALF] + training_images_women[TRAINING_SIZE_HALF:VALIDATION_SIZE_HALF])\n",
    "testing_data, testing_images = compile(testing_images)"
   ]
  },
  {
   "source": [
    "# Flatten the images into one numpy array"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(16, (8, 8), input_shape = [128, 128, 3], strides = 1, padding = \"same\", activation = \"relu\", name = \"convolution_large\"),\n",
    "        keras.layers.MaxPool2D(pool_size = (2, 2), padding = \"valid\", name = \"pooling\"),\n",
    "        keras.layers.Conv2D(16, (4, 4), input_shape = [64, 64, 16], strides = 1, padding = \"same\", activation = \"relu\", name = \"convolution_small\"),\n",
    "        keras.layers.Flatten(name = \"flatten\"),\n",
    "        keras.layers.Dense(16 * 4 * 4, activation = tensorflow.nn.softmax, name = \"fully_connected_1\"),\n",
    "        keras.layers.Dense(2, activation = tensorflow.nn.softmax, name = \"fully_connected_2\")\n",
    "    ])\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = keras.optimizers.RMSprop(), metrics = [ \"accuracy\" ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barnet = create_model()\n",
    "barnet.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.History(),\n",
    "    keras.callbacks.EarlyStopping(monitor = \"loss\", patience = 10, verbose = 1, mode = \"auto\")\n",
    "]"
   ]
  },
  {
   "source": [
    "# TRAIN!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barnet.fit(training_data, training_labels, batch_size = BATCH_SIZE, epochs = 20, validation_data = (validation_data, validation_labels), verbose = 2, shuffle = True, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = vgg.evaluate(validation_data, validation_labels, verbose = 1)\n",
    "print(f\"Loss: {test_loss}\\nAccuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}